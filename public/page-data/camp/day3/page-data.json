{
    "componentChunkName": "component---src-templates-camp-curriculum-js",
    "path": "/camp/day3",
    "result": {"data":{"markdownRemark":{"html":"<h2>Introduction</h2>\n<p>Today, we will take another step in our overall goal of creating a smart security system. Through our camera feed, we want to determine whether there is someone (or something) in the frame. To do this, we will use our knowledge of <code class=\"language-text\">OpenCV</code> to detect motion.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/022db0dd8799136a6a0043b36eb12cd4/a18e1/day3_motion.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAQBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe/LRGXsAGg//8QAGhAAAgIDAAAAAAAAAAAAAAAAAgMAARIgMf/aAAgBAQABBQKJYZ3C4jK9f//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQMBAT8BH//EABQRAQAAAAAAAAAAAAAAAAAAACD/2gAIAQIBAT8BH//EABsQAAEEAwAAAAAAAAAAAAAAAAEAAhESECAh/9oACAEBAAY/AkbMrGOImdf/xAAcEAABBQADAAAAAAAAAAAAAAABABARITFBgaH/2gAIAQEAAT8hOVqo2U7YCTlBUggb5w8AN//aAAwDAQACAAMAAAAQcMgA/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPxAf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPxAf/8QAHBABAAEFAQEAAAAAAAAAAAAAAREAECExQVFx/9oACAEBAAE/EJSgMMTQB3hZnqwQPo1HlDMFfgPEzOs6skkNGgBzBb//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"day3 motion\"\n        title=\"day3 motion\"\n        src=\"/static/022db0dd8799136a6a0043b36eb12cd4/b4294/day3_motion.jpg\"\n        srcset=\"/static/022db0dd8799136a6a0043b36eb12cd4/75985/day3_motion.jpg 150w,\n/static/022db0dd8799136a6a0043b36eb12cd4/f93b5/day3_motion.jpg 300w,\n/static/022db0dd8799136a6a0043b36eb12cd4/b4294/day3_motion.jpg 600w,\n/static/022db0dd8799136a6a0043b36eb12cd4/a18e1/day3_motion.jpg 612w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>How do we achieve this?</p>\n<p>Well, first we need a way to stream the camera feed. In the past, we successfully captured still images from the camera, and even showed a preview of the feed for a few seconds. But now, we need a way to access the camera feed in a Python script.</p>\n<p>We would then need to figure out a way to detect any motion in the stream. We'll get back to this later, but for now, think of some ideas about how we can detect motion. Think about what exactly the \"motion\" is in terms of a stream of images. After all, a video is just a set of still images that you view in rapid succession.</p>\n<h2>1. Steady Camera Stream</h2>\n<p>First things first, let's stream the camera in Python. To do this, we will need the <code class=\"language-text\">picamera</code> module. Run the following in the terminal to download the necessary packages:</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ python3 -c <span class=\"token string\">\"import picamera\"</span>\n<span class=\"token comment\"># TODO install these packages on day1</span>\n$ pip3 <span class=\"token function\">install</span> opencv-contrib-python \n$ <span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> -y libatlas-base-dev libhdf5-dev libhdf5-serial-dev libatlas-base-dev libjasper-dev  libqtgui4  libqt4-test\n$ pip3 <span class=\"token function\">install</span> -U numpy </code></pre></div>\n<h3>a) Access Single Images</h3>\n<p>Let's start by accessing a single image from the camera stream. Create a new Python file called <code class=\"language-text\">motion_detection.py</code></p>\n<p>First, import the required libraries</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># import the necessary packages</span>\n<span class=\"token keyword\">from</span> picamera<span class=\"token punctuation\">.</span>array <span class=\"token keyword\">import</span> PiRGBArray\n<span class=\"token keyword\">from</span> picamera <span class=\"token keyword\">import</span> PiCamera\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">import</span> cv2</code></pre></div>\n<p>We then need to initialize a camera by calling <code class=\"language-text\">PiCamera()</code>. This will give us a reference to the raw camera capture component. The <code class=\"language-text\">raw_capture</code> object is especially useful since it gives us direct access to the camera stream and avoids the expensive compression to JPEG format, which we would then have to take and decode to <code class=\"language-text\">OpenCV</code> format anyway.</p>\n<p>Let's also change the camera resolution to <code class=\"language-text\">640x480</code> pixels. This dimension is arbitrary, but it will standardize our outputs later on.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber 0\" class=\"language-python line-numbers\"><code class=\"language-python\">camera <span class=\"token operator\">=</span> PiCamera<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncamera<span class=\"token punctuation\">.</span>resolution <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">640</span><span class=\"token punctuation\">,</span> <span class=\"token number\">480</span><span class=\"token punctuation\">)</span>\nraw_capture <span class=\"token operator\">=</span> PiRGBArray<span class=\"token punctuation\">(</span>camera<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">640</span><span class=\"token punctuation\">,</span> <span class=\"token number\">480</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntime<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># allow time for the camera to warmup</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span></span></pre></div>\n<p>Next, we will capture a frame by calling <code class=\"language-text\">capture()</code> on the camera object we previously created. Being aware that the format is <code class=\"language-text\">BGR</code> and not the traditional <code class=\"language-text\">RGB</code>. This is extremely important because <code class=\"language-text\">OpenCV</code> represents images as <code class=\"language-text\">Numpy</code> arrays in <code class=\"language-text\">BGR</code> order rather than <code class=\"language-text\">RGB</code>. This little nuance is subtle, but very important to remember as it can lead to some confusing bugs in your code down the line.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># grab an image from the camera</span>\ncamera<span class=\"token punctuation\">.</span>capture<span class=\"token punctuation\">(</span>raw_capture<span class=\"token punctuation\">,</span> <span class=\"token builtin\">format</span><span class=\"token operator\">=</span><span class=\"token string\">\"bgr\"</span><span class=\"token punctuation\">)</span>\nimage <span class=\"token operator\">=</span> raw_capture<span class=\"token punctuation\">.</span>array</code></pre></div>\n<p>Now, let's display the image on the screen by using <code class=\"language-text\">cv2.imshow()</code>.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">cv2<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span><span class=\"token string\">\"Image\"</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span>\ncv2<span class=\"token punctuation\">.</span>waitKey<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># wait indefinitely until a key is pressed</span></code></pre></div>\n<p>Test that this is working by running</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ python3 motion_detection.py</code></pre></div>\n<h3>b) Constant Streaming</h3>\n<p>Now that we have successfully used <code class=\"language-text\">OpenCV</code> to grab a single image from the camera, let’s move on to a video stream.</p>\n<p>The concept is similar to how we got a single image above. But instead of calling <code class=\"language-text\">capture</code> on the camera object, we will call <code class=\"language-text\">capture_continuous</code> instead. Intuitively right?</p>\n<p>But in order to process each individual frame in this continuous stream, we will need a for loop:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">for</span> frame <span class=\"token keyword\">in</span> camera<span class=\"token punctuation\">.</span>capture_continuous<span class=\"token punctuation\">(</span>raw_capture<span class=\"token punctuation\">,</span> <span class=\"token builtin\">format</span><span class=\"token operator\">=</span><span class=\"token string\">\"bgr\"</span><span class=\"token punctuation\">,</span> use_video_port<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    image <span class=\"token operator\">=</span> frame<span class=\"token punctuation\">.</span>array</code></pre></div>\n<p>The <code class=\"language-text\">capture_continuous</code> method returns a frame from the video stream. The frame then has an array property, which corresponds to the frame in <code class=\"language-text\">Numpy</code> array format. So, in order to get the image frame itself, we have to call <code class=\"language-text\">frame.array</code> to get the <code class=\"language-text\">Numpy</code> array representation of the image.</p>\n<p>Also, within the loop, we have to clear the <code class=\"language-text\">raw_capture</code> stream to get ready for the next frame.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">raw_capture<span class=\"token punctuation\">.</span>truncate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nraw_capture<span class=\"token punctuation\">.</span>seek<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Finally, let’s wait for an \"escape\" key to be pressed in order to exit out of the infinite loop.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">key <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>waitKey<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token comment\"># get the key pressed in the last millisecond</span>\n<span class=\"token keyword\">if</span> key <span class=\"token operator\">==</span> <span class=\"token builtin\">ord</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"q\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">break</span></code></pre></div>\n<p>In summary, you should have the following code in <code class=\"language-text\">motion_detection.py</code></p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber 0\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> picamera<span class=\"token punctuation\">.</span>array <span class=\"token keyword\">import</span> PiRGBArray\n<span class=\"token keyword\">from</span> picamera <span class=\"token keyword\">import</span> PiCamera\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">import</span> cv2\n<span class=\"token comment\"># initialize the camera and grab a reference to the raw camera capture</span>\ncamera <span class=\"token operator\">=</span> PiCamera<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncamera<span class=\"token punctuation\">.</span>resolution <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">640</span><span class=\"token punctuation\">,</span> <span class=\"token number\">480</span><span class=\"token punctuation\">)</span>\nraw_capture <span class=\"token operator\">=</span> PiRGBArray<span class=\"token punctuation\">(</span>camera<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">640</span><span class=\"token punctuation\">,</span> <span class=\"token number\">480</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># allow the camera to warmup</span>\ntime<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># capture frames from the camera</span>\n<span class=\"token keyword\">for</span> frame <span class=\"token keyword\">in</span> camera<span class=\"token punctuation\">.</span>capture_continuous<span class=\"token punctuation\">(</span>raw_capture<span class=\"token punctuation\">,</span> <span class=\"token builtin\">format</span><span class=\"token operator\">=</span><span class=\"token string\">\"bgr\"</span><span class=\"token punctuation\">,</span> use_video_port<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\t<span class=\"token comment\"># grab the raw NumPy array representing the image, then initialize the timestamp</span>\n\t<span class=\"token comment\"># and occupied/unoccupied text</span>\n\timage <span class=\"token operator\">=</span> frame<span class=\"token punctuation\">.</span>array\n\t<span class=\"token comment\"># show the frame</span>\n\tcv2<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span><span class=\"token string\">\"Frame\"</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span>\n\t<span class=\"token comment\"># clear the stream in preparation for the next frame</span>\n\traw_capture<span class=\"token punctuation\">.</span>truncate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    \traw_capture<span class=\"token punctuation\">.</span>seek<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n    \n    \t<span class=\"token comment\"># exit the loop when `q` is pressed</span>\n    \tkey <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>waitKey<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\t<span class=\"token keyword\">if</span> key <span class=\"token operator\">==</span> <span class=\"token builtin\">ord</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"q\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        \t<span class=\"token keyword\">break</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>To run this program, go to the terminal and execute</p>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">$ python3 motion_detection.py</code></pre></div>\n<h2>2. What's the Difference?</h2>\n<p>Now, let's revisit our initial question. How do we detect motion within a camera stream? Hint: think of the camera stream as a series of image frames that are just shown in rapid succession.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/eb3a64b70a0b82c64d6a99677b70bea9/b8220/day3_frames.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDBAb/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHW1Isc+H//xAAcEAABAwUAAAAAAAAAAAAAAAABAAIRAxITIUL/2gAIAQEAAQUC0umxBJBe82Zqi//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABsQAAIBBQAAAAAAAAAAAAAAAAACMgEQQWGR/9oACAEBAAY/AniLExZq6Jt0/8QAHRAAAgMAAgMAAAAAAAAAAAAAAREAITEQsUFh8P/aAAgBAQABPyE4d+5VAZfKKL38XDAPcrIiCkQ4Z//aAAwDAQACAAMAAAAQow//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAeEAEBAAICAgMAAAAAAAAAAAABEQAhMXFBgVFhwf/aAAgBAQABPxCjBDKft46MGtI1R3J4fH25MAdqOL3gRLy0T194RvOSWzmzATRdLP/Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"day3 frames\"\n        title=\"day3 frames\"\n        src=\"/static/eb3a64b70a0b82c64d6a99677b70bea9/b4294/day3_frames.jpg\"\n        srcset=\"/static/eb3a64b70a0b82c64d6a99677b70bea9/75985/day3_frames.jpg 150w,\n/static/eb3a64b70a0b82c64d6a99677b70bea9/f93b5/day3_frames.jpg 300w,\n/static/eb3a64b70a0b82c64d6a99677b70bea9/b4294/day3_frames.jpg 600w,\n/static/eb3a64b70a0b82c64d6a99677b70bea9/b8220/day3_frames.jpg 733w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>What exactly is \"motion\" anyways? In the example above, we see that there are minor differences between each frame. If you put all of these minor differences together, you get \"motion\".</p>\n<p><img src=\"day3_frames_animated.gif\" alt=\"\"></p>\n<p>Today, we will explore what it means to use background subtraction between frames to detect motion.</p>\n<h3>What is Background Subtraction</h3>\n<p>Background subtraction is critical in many Computer Vision applications. We use it to count the number of cars passing through a toll booth. We use it to count the number of people walking in and out of a store.</p>\n<p>And we will now use it for motion detection.</p>\n<p>The base of this approach is that of detecting moving objects from the difference between the current frame and reference frame, which is often called ‘Background Image’ or ‘Background Model’. This background subtraction is typically done by detecting the foreground objects in a video frame and foreground detection is the main task of this whole approach.</p>\n<p>Any robust background subtraction model should be able to handle light intensity changes and repeated motion from long term scene changes. The analysis of such an approach mathematically can be modeled using a function <code class=\"language-text\">P(x,y,t)</code> as a video sequence where <code class=\"language-text\">t</code> is the time dimensions <code class=\"language-text\">x</code> and <code class=\"language-text\">y</code> are the pixel locations.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 580px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/02dc41d365bc9c1a1134922a55da59f9/b6272/day3_background_subtraction.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 44.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAB7UlEQVQoz12S20sbQRhH/U+LLfggtiUQ22SbTVZzJTEXN9lNFC1aYxVBW1pMG6MUqlhta61Sw9aSPMR6CSEPig0ht1N2YFPsD5aZ+eZw9tudGej1epiPmaurK0qlEpVKhYuLC1qtFlba7TZnZ2eUy2Uxmsz5+XmfsTwD1qLb7dLpdLi8vBRwo9Ho181Y+/V6HcMwqNVq/ZrVkBBaCys3N9fc/rm9U7tLQLVa5f9YHtHhr1KJ/MYGm1sf2MwXWFla4eDoB3vHBkb5t0mz//mAQmGL7Y87vH39hvfv8hwWT9k9NKjVr/91aE7Wc3nsT134gmFc8hjxcIx4JMqIzUl2eVXAE/EUypgf73gAvzeAFk8QCkZ4ZHdxcmLcFX75+o0nkoKqTRNLqCi+ILMzz9FTGq/W1gQ8N7+AU/Kga2n8/iCR8ATL2UW0ZBKjWBSMeUBCuL2zSyAYYdTpRtOmCEeijEoyoUiU9VyOZrPJ/Is5FMWLJLnR9TRut4JDklGTKU5PfwrG/LdCuLiQxSO78QZC4rNTqkZCTTE0/JDsyyXxdkVxE08kcDplHA6Zqcw0414/wyOP+X503L8JQpjRpxgavIeeSeN4JmO3O1Ank/gCIWKTmoAfDN7HJctEozFsNjuSJDM7M4tL9vBpb78v/AuFQVRre7LvUgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"day3 background subtraction\"\n        title=\"day3 background subtraction\"\n        src=\"/static/02dc41d365bc9c1a1134922a55da59f9/b6272/day3_background_subtraction.png\"\n        srcset=\"/static/02dc41d365bc9c1a1134922a55da59f9/8a4e8/day3_background_subtraction.png 150w,\n/static/02dc41d365bc9c1a1134922a55da59f9/5a46d/day3_background_subtraction.png 300w,\n/static/02dc41d365bc9c1a1134922a55da59f9/b6272/day3_background_subtraction.png 580w\"\n        sizes=\"(max-width: 580px) 100vw, 580px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Mathematically it can be modeled as:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">|reference_frame – current_frame| > Threshold</code></pre></div>\n<p>This approach can be used when segmenting motion-based objects such as cars, pedestrians etc.</p>\n<p>And it is very sensitive to threshold values. So depending on object structure, speed, frame rate and global threshold limit, this approach has limited use cases.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 473px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/5c5897ec89d5f83c5ad7099877c35c3b/c7c3c/day3_threshold.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACVUlEQVQ4y6VTS0tyURQ9WWZg4YMitAaFj4FQIEg4rEkT8U9Y4MDqH/gDTEFEyIGOfeRjKBoEGtTUQY+h0CAikx6gJWqu2BvOtQ9r9B1Y3HvOWXvd/VhX4Mfqdrt4fX3FcDhUzkaj0cST8PX1hff3d+Z/fn4qd4IuWq0Wnp+f8fDwgPv7e34+Pj6i3W7/KipXv9/Hx8fHP+ei2WzC4XBgfX0dNpsNy8vLMJlMmJ+fx/b2tiI0GAz4vVKpwO12Y3d3l+8JOzs7cDqdiEajEDc3NxBCwGg0shgJ0Z5AH5KClA2tk5MTvpuamlJ4Evv7+xC3t7eYmZmB2WzG6uoq7HY7Njc3OWBra2tCMJlMcvDKygonQdUYDAY+Ozo6gri7u4NKpeIDi8WCjY0NLC0tMfG3DFOpFHOnp6eVFq2trfE+EAhAXF9fQ61WM2lxcZFFZAkul2tCMB6PK/eU4ezsrLL3+XwQnU4HV1dXjGq1inK5jFqthouLC1D2UpDcQIsSOD4+RiwWQzgcRigUQiQS4fd6vQ4hyeS9l5cXPD094e3tjYOlyF+2IcuQ5Xq93tg2lBk12Gq1cg8J1Bvq497eniIsbZNOp6HT6ZhHVpMxer0ewWAQ4uzsjOuXg/kJ8poUlD1MJBITPAm/3w9xfn7Om4WFBfagVqtVvOj1eicEpW1oGJQEQQ718PBwLEigMil1EiSix+P5U5BEyCrkVyl4cHAwLpmg0WgwNzf3fyXTVHO5HIrFIk5PT5HP51EqlZDNZnF5eTlhG/r3aTDEKRQKDIrNZDJoNBr4BgvP/gD+CgwIAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"day3 threshold\"\n        title=\"day3 threshold\"\n        src=\"/static/5c5897ec89d5f83c5ad7099877c35c3b/c7c3c/day3_threshold.png\"\n        srcset=\"/static/5c5897ec89d5f83c5ad7099877c35c3b/8a4e8/day3_threshold.png 150w,\n/static/5c5897ec89d5f83c5ad7099877c35c3b/5a46d/day3_threshold.png 300w,\n/static/5c5897ec89d5f83c5ad7099877c35c3b/c7c3c/day3_threshold.png 473w\"\n        sizes=\"(max-width: 473px) 100vw, 473px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>We will use background subtraction to detect motion because the background of our video stream is largely static and unchanging over consecutive frames of a video. Therefore, if we can model the background, we monitor it for substantial changes. If there is a substantial change, we can detect it — this change normally corresponds to motion in our video.</p>\n<h3>Implement Background Subtraction</h3>\n<p>Let's go back to our previous <code class=\"language-text\">motion_detection.py</code> file.</p>\n<p>Instead of showing the frame or image by 'cv2.imshow(\"Frame\", image)', we should check if <code class=\"language-text\">image</code> is <code class=\"language-text\">None</code>; as well as setting a default message of \"Not Detected\" to variable maybe_motion_text and later change it once we detect any motion.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">maybe_motion_text <span class=\"token operator\">=</span> <span class=\"token string\">\"Not Detected\"</span>\n<span class=\"token keyword\">if</span> image <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">break</span></code></pre></div>\n<p>Then, We will need to augment the incoming images. Let's convert the image to grayscale, as color has no bearing on motion detection other than adding noise to the data. We also apply Gaussian blurring to smooth our images.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">current_frame <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>cvtColor<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span>cv2<span class=\"token punctuation\">.</span>COLOR_BGR2GRAY<span class=\"token punctuation\">)</span>\ncurrent_frame <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>GaussianBlur<span class=\"token punctuation\">(</span>current_frame<span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span><span class=\"token number\">21</span><span class=\"token punctuation\">,</span><span class=\"token number\">21</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Due to tiny variations in the digital camera sensors, no two frames will be 100% the same — some pixels will most certainly have different intensity values. That said, we need to account for this and apply Gaussian smoothing to average pixel intensities across an 21 x 21 region. This helps smooth out high frequency noise that could throw our motion detection algorithm off.</p>\n<p>For simplicity, let’s assume that the first frame we capture will contain no motion and just background. (Make sure the assumption is satisfied when you run the program.) So, we will store the first image input as the reference frame. Don't forget to set reference_frame to None initially!</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">if</span> reference_frame <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n    reference_frame <span class=\"token operator\">=</span> current_frame\n    <span class=\"token keyword\">continue</span></code></pre></div>\n<p>Here, if we see that there is currently no reference frame, we will use the image input as the reference frame and continue on to the next frame.</p>\n<p>Now that we have our background modeled via the <code class=\"language-text\">reference_frame</code> variable, we can utilize it to compute the difference between the initial frame and subsequent new frames from the video stream.</p>\n<p>Let's compute the absolute difference between the current frame and the reference frame.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">frame_delta <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>absdiff<span class=\"token punctuation\">(</span>reference_frame<span class=\"token punctuation\">,</span>current_frame<span class=\"token punctuation\">)</span>\nthresh <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>threshold<span class=\"token punctuation\">(</span>frame_delta<span class=\"token punctuation\">,</span> <span class=\"token number\">25</span><span class=\"token punctuation\">,</span> <span class=\"token number\">255</span><span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>THRESH_BINARY<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span></code></pre></div>\n<p>Dilation fills holes and connects areas; it makes small differences a bit clearer by increasing the size and brightness. Thus, we can unite the little boxes together to form bigger detecting bounding boxes.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">thresh <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>dilate<span class=\"token punctuation\">(</span>thresh<span class=\"token punctuation\">,</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>iterations<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>This will take the pixel density difference between the current and reference frames using the following formula:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">delta = |reference_frame – current_frame|</code></pre></div>\n<p>Now, we can use <code class=\"language-text\">cv2.threshold</code> to reveal regions of the image that only have significant changes in pixel intensity values. If the delta is less than 25, we discard the pixel and set it to black (i.e. background). If the delta is greater than 25, we’ll set it to white (i.e. foreground).</p>\n<p>It will look something like this:\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 600px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/1a30f317cfa59cc4ca6b315b4d0ff98e/a2510/day3_frame_delta_thresholded.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 35.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAHABQDASIAAhEBAxEB/8QAFwABAAMAAAAAAAAAAAAAAAAAAAEEBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAc2Aug//xAAXEAADAQAAAAAAAAAAAAAAAAABAxIC/9oACAEBAAEFAtF1ZLaQWR//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAdEAABAwUBAAAAAAAAAAAAAAACAAERISIxUXGR/9oACAEBAAY/AiuL1NJnHVUnztf/xAAZEAEAAgMAAAAAAAAAAAAAAAABABEhUWH/2gAIAQEAAT8h6LalIGTlJurrtP8A/9oADAMBAAIAAwAAABAAD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAQACAgMAAAAAAAAAAAAAAAEAIRFRYXGR/9oACAEBAAE/EK8QYg99wuzBlQ9i7yLRrBzP/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"day3 frame delta thresholded\"\n        title=\"day3 frame delta thresholded\"\n        src=\"/static/1a30f317cfa59cc4ca6b315b4d0ff98e/b4294/day3_frame_delta_thresholded.jpg\"\n        srcset=\"/static/1a30f317cfa59cc4ca6b315b4d0ff98e/75985/day3_frame_delta_thresholded.jpg 150w,\n/static/1a30f317cfa59cc4ca6b315b4d0ff98e/f93b5/day3_frame_delta_thresholded.jpg 300w,\n/static/1a30f317cfa59cc4ca6b315b4d0ff98e/b4294/day3_frame_delta_thresholded.jpg 600w,\n/static/1a30f317cfa59cc4ca6b315b4d0ff98e/8e1fc/day3_frame_delta_thresholded.jpg 900w,\n/static/1a30f317cfa59cc4ca6b315b4d0ff98e/a2510/day3_frame_delta_thresholded.jpg 1000w\"\n        sizes=\"(max-width: 600px) 100vw, 600px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>Given this thresholded image, it’s simple to apply contour detection to find the outlines of these white regions. Don't forget to import imutils!</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">cnts <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>findContours<span class=\"token punctuation\">(</span>thresh<span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>RETR_EXTERNAL<span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>CHAIN_APPROX_SIMPLE<span class=\"token punctuation\">)</span>\ncnts <span class=\"token operator\">=</span> imutils<span class=\"token punctuation\">.</span>grab_contours<span class=\"token punctuation\">(</span>cnts<span class=\"token punctuation\">)</span></code></pre></div>\n<p>We will now loop over each of the contours, where we’ll filter the small, irrelevant contours. If the contour area is larger than a pre-determined <code class=\"language-text\">min_area</code> value, we’ll draw the bounding box surrounding the foreground and motion region. We will use 15 as a default value for min_area so don't forget to initialize your 'min_area' as 15.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber 0\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> cnts<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> cv2<span class=\"token punctuation\">.</span>contourArea<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> min_area<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">continue</span>\n        <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span>w<span class=\"token punctuation\">,</span>h<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>boundingRect<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span>\n        cv2<span class=\"token punctuation\">.</span>rectangle<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span>x<span class=\"token operator\">+</span>w<span class=\"token punctuation\">,</span>y<span class=\"token operator\">+</span>h<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">255</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span></span></pre></div>\n<p>And that is all! We have just detected motion!</p>\n<p>To review, here is what we accomplished:</p>\n<ol>\n<li>use the first frame in the camera feed as the reference frame</li>\n<li>process each frame in a constant camera feed against the reference frame</li>\n<li>each frame is converted to grayscale and a Gaussian blur was applied (can you remember why the Gaussian filter was needed?)</li>\n<li>take the difference in pixel density between the reference frame and each subsequence frame</li>\n<li>find the \"contours\", where there is an obvious difference in pixel density (above a given threshold)</li>\n<li>for each contour, if it is larger than a pre-determined min_area threshold, draw a bounding box to label it as detected motion</li>\n</ol>\n<h3>Wrapping Up</h3>\n<p>To wrap up, let's visualize everything we have computed above using <code class=\"language-text\">cv2.imshow</code>.</p>\n<p>First, let's show whether motion was or was not detected, along with the date. Don't forget to import datetime!</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">cv2<span class=\"token punctuation\">.</span>putText<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token string\">\"Motion: {}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>maybe_motion_text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>FONT_HERSHEY_SIMPLEX<span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">255</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\ncv2<span class=\"token punctuation\">.</span>putText<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> datetime<span class=\"token punctuation\">.</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">\"%A %d %B %Y %I: %M: %S%p\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>image<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">-</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>FONT_HERSHEY_SIMPLEX<span class=\"token punctuation\">,</span> <span class=\"token number\">0.35</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">255</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Here, we use a <code class=\"language-text\">maybe_motion_text</code> variable to store whether there was motion. Think about where you need to initialize this variable and when to change it in your code. If you need help, look to the full code script below.</p>\n<p>Now, let's open up three windows.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">cv2<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span><span class=\"token string\">\"Feed\"</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span>\ncv2<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span><span class=\"token string\">\"Threshold\"</span><span class=\"token punctuation\">,</span> thresh<span class=\"token punctuation\">)</span>\ncv2<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span><span class=\"token string\">\"Frame Delta\"</span><span class=\"token punctuation\">,</span> frame_delta<span class=\"token punctuation\">)</span></code></pre></div>\n<p>The first window will be our image (with bounding boxes around any detected motion). We will also open windows to show the frame delta and thresholded images (just for fun :D).</p>\n<h3>Full Python Program</h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre style=\"counter-reset: linenumber 0\" class=\"language-python line-numbers\"><code class=\"language-python\"><span class=\"token keyword\">from</span> picamera<span class=\"token punctuation\">.</span>array <span class=\"token keyword\">import</span> PiRGBArray\n<span class=\"token keyword\">from</span> picamera <span class=\"token keyword\">import</span> PiCamera\n<span class=\"token keyword\">import</span> imutils\n<span class=\"token keyword\">import</span> datetime\n<span class=\"token keyword\">import</span> time\n<span class=\"token keyword\">import</span> cv2\n\ncamera <span class=\"token operator\">=</span> PiCamera<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncamera<span class=\"token punctuation\">.</span>resolution <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token number\">640</span><span class=\"token punctuation\">,</span> <span class=\"token number\">480</span><span class=\"token punctuation\">)</span>\nraw_capture <span class=\"token operator\">=</span> PiRGBArray<span class=\"token punctuation\">(</span>camera<span class=\"token punctuation\">,</span> size<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">640</span><span class=\"token punctuation\">,</span> <span class=\"token number\">480</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\ntime<span class=\"token punctuation\">.</span>sleep<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\nreference_frame <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n\nmin_area <span class=\"token operator\">=</span> <span class=\"token number\">15</span>\n\n<span class=\"token keyword\">for</span> frame <span class=\"token keyword\">in</span> camera<span class=\"token punctuation\">.</span>capture_continuous<span class=\"token punctuation\">(</span>raw_capture<span class=\"token punctuation\">,</span> <span class=\"token builtin\">format</span><span class=\"token operator\">=</span><span class=\"token string\">\"bgr\"</span><span class=\"token punctuation\">,</span> use_video_port<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    image <span class=\"token operator\">=</span> frame<span class=\"token punctuation\">.</span>array\n    raw_capture<span class=\"token punctuation\">.</span>truncate<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    raw_capture<span class=\"token punctuation\">.</span>seek<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n    \n    maybe_motion_text <span class=\"token operator\">=</span> <span class=\"token string\">\"Not Detected\"</span>\n    <span class=\"token keyword\">if</span> image <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">break</span>\n\n    current_frame <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>cvtColor<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span>cv2<span class=\"token punctuation\">.</span>COLOR_BGR2GRAY<span class=\"token punctuation\">)</span>\n    current_frame <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>GaussianBlur<span class=\"token punctuation\">(</span>current_frame<span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span><span class=\"token number\">21</span><span class=\"token punctuation\">,</span><span class=\"token number\">21</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">if</span> reference_frame <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n        reference_frame <span class=\"token operator\">=</span> current_frame\n        <span class=\"token keyword\">continue</span>\n        \n    frame_delta <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>absdiff<span class=\"token punctuation\">(</span>reference_frame<span class=\"token punctuation\">,</span>current_frame<span class=\"token punctuation\">)</span>\n    thresh <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>threshold<span class=\"token punctuation\">(</span>frame_delta<span class=\"token punctuation\">,</span> <span class=\"token number\">25</span><span class=\"token punctuation\">,</span><span class=\"token number\">255</span><span class=\"token punctuation\">,</span>cv2<span class=\"token punctuation\">.</span>THRESH_BINARY<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n    \n    thresh <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>dilate<span class=\"token punctuation\">(</span>thresh<span class=\"token punctuation\">,</span><span class=\"token boolean\">None</span><span class=\"token punctuation\">,</span>iterations<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n    cnts <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>findContours<span class=\"token punctuation\">(</span>thresh<span class=\"token punctuation\">.</span>copy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>RETR_EXTERNAL<span class=\"token punctuation\">,</span>\n            cv2<span class=\"token punctuation\">.</span>CHAIN_APPROX_SIMPLE<span class=\"token punctuation\">)</span>\n    cnts <span class=\"token operator\">=</span> imutils<span class=\"token punctuation\">.</span>grab_contours<span class=\"token punctuation\">(</span>cnts<span class=\"token punctuation\">)</span>\n        \n    <span class=\"token keyword\">for</span> c <span class=\"token keyword\">in</span> cnts<span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">if</span> cv2<span class=\"token punctuation\">.</span>contourArea<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span> <span class=\"token operator\">&lt;</span> min_area<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">continue</span>\n        <span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">,</span>w<span class=\"token punctuation\">,</span>h<span class=\"token punctuation\">)</span> <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>boundingRect<span class=\"token punctuation\">(</span>c<span class=\"token punctuation\">)</span>\n        cv2<span class=\"token punctuation\">.</span>rectangle<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">,</span>y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span>x<span class=\"token operator\">+</span>w<span class=\"token punctuation\">,</span>y<span class=\"token operator\">+</span>h<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">255</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        maybe_motion_text <span class=\"token operator\">=</span> <span class=\"token string\">\"Detected\"</span>\n        \n    cv2<span class=\"token punctuation\">.</span>putText<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> <span class=\"token string\">\"Motion: {}\"</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>maybe_motion_text<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span><span class=\"token number\">20</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>FONT_HERSHEY_SIMPLEX<span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">255</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n    cv2<span class=\"token punctuation\">.</span>putText<span class=\"token punctuation\">(</span>image<span class=\"token punctuation\">,</span> datetime<span class=\"token punctuation\">.</span>datetime<span class=\"token punctuation\">.</span>now<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>strftime<span class=\"token punctuation\">(</span><span class=\"token string\">\"%A %d %B %Y %I: %M: %S%p\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">,</span>image<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token operator\">-</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>FONT_HERSHEY_SIMPLEX<span class=\"token punctuation\">,</span> <span class=\"token number\">0.35</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span><span class=\"token number\">255</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        \n    cv2<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span><span class=\"token string\">\"Feed\"</span><span class=\"token punctuation\">,</span> image<span class=\"token punctuation\">)</span>\n    cv2<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span><span class=\"token string\">\"Threshold\"</span><span class=\"token punctuation\">,</span> thresh<span class=\"token punctuation\">)</span>\n    cv2<span class=\"token punctuation\">.</span>imshow<span class=\"token punctuation\">(</span><span class=\"token string\">\"Frame Delta\"</span><span class=\"token punctuation\">,</span> frame_delta<span class=\"token punctuation\">)</span>\n    \n    key <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>waitKey<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> key <span class=\"token operator\">==</span> <span class=\"token builtin\">ord</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"q\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token keyword\">break</span>\n\ncv2<span class=\"token punctuation\">.</span>destroyAllWindows<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code><span aria-hidden=\"true\" class=\"line-numbers-rows\" style=\"white-space: normal; width: auto; left: 0;\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></pre></div>","frontmatter":{"date":"June 22, 2022","slug":"/camp/day3","title":"Day 3"}}},"pageContext":{"slug":"/camp/day3"}},
    "staticQueryHashes": []}